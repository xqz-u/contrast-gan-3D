{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# https://discuss.pytorch.org/t/gpu-device-ordering/60785/2\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from batchgenerators.dataloading.single_threaded_augmenter import \\\n",
    "    SingleThreadedAugmenter\n",
    "from batchgenerators.utilities.file_and_folder_operations import load_pickle\n",
    "from torch import Tensor\n",
    "\n",
    "from contrast_gan_3D import config, utils\n",
    "from contrast_gan_3D.alias import ScanType\n",
    "from contrast_gan_3D.data import utils as data_u\n",
    "from contrast_gan_3D.eval.CCTAContrastCorrector import CCTAContrastCorrector\n",
    "# from contrast_gan_3D.experiments.basic_conf import *\n",
    "from contrast_gan_3D.experiments.conf_2D import *\n",
    "from contrast_gan_3D.model import utils as model_utils\n",
    "# from contrast_gan_3D.experiments.test_conf_2D import *\n",
    "# from contrast_gan_3D.experiments.gradient_penalty_conf import *\n",
    "from contrast_gan_3D.model.loss import HULoss\n",
    "from contrast_gan_3D.trainer import utils as train_u\n",
    "from contrast_gan_3D.trainer.logger.LoggerInterface import SingleThreadedLogger\n",
    "from contrast_gan_3D.trainer.Trainer import Trainer\n",
    "from contrast_gan_3D.utils import set_GPU\n",
    "from contrast_gan_3D.utils import visualization as viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = load_pickle(\"/home/marco/thesis_project/contrast-gan-3D/cross_val_splits.pkl\")\n",
    "print(len(splits))\n",
    "\n",
    "train_fold, val_fold = splits[\"train\"][0], splits[\"test\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_interface = SingleThreadedLogger(logger_interface.logger)\n",
    "\n",
    "# chosen_bs = train_batch_size\n",
    "chosen_bs = {\n",
    "    v.value: b for v, b in [(ScanType.OPT, 1), (ScanType.LOW, 1), (ScanType.HIGH, 1)]\n",
    "}\n",
    "# chosen_ps = train_patch_size\n",
    "chosen_ps = val_patch_size\n",
    "\n",
    "subopt_bs = (\n",
    "    chosen_bs[ScanType.LOW.value] + chosen_bs[ScanType.HIGH.value],\n",
    "    1,\n",
    "    *chosen_ps,\n",
    ")\n",
    "opt_bs = (chosen_bs[ScanType.OPT.value], 1, *chosen_ps)\n",
    "print(subopt_bs, opt_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loaders, val_loaders = train_u.create_dataloaders(\n",
    "    train_fold,\n",
    "    val_fold,\n",
    "    train_patch_size,\n",
    "    val_patch_size,\n",
    "    chosen_bs,\n",
    "    chosen_bs,\n",
    "    rng,\n",
    "    scaler=scaler,\n",
    "    num_workers=num_workers,\n",
    "    train_transform=train_transform,\n",
    "    seed=seed,\n",
    ")\n",
    "\n",
    "train_loaders = {\n",
    "    k: SingleThreadedAugmenter(v.generator, v.transform)\n",
    "    for k, v in train_loaders.items()\n",
    "}\n",
    "val_loaders = {\n",
    "    k: SingleThreadedAugmenter(v.generator, v.transform)\n",
    "    for k, v in val_loaders.items()\n",
    "}\n",
    "\n",
    "# chosen_loaders = train_loaders\n",
    "chosen_loaders = val_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_HU_bounds = scaler(np.array(desired_HU_bounds))\n",
    "print(scaled_HU_bounds)\n",
    "\n",
    "device = set_GPU(7)\n",
    "\n",
    "log_images_every, train_generator_every, log_every = 1, 1, 1\n",
    "\n",
    "trainer = Trainer(\n",
    "    train_iterations,\n",
    "    val_iterations,\n",
    "    validate_every,\n",
    "    train_generator_every,\n",
    "    train_critic_every,\n",
    "    log_every,\n",
    "    log_images_every,\n",
    "    generator_class,\n",
    "    critic_class,\n",
    "    generator_optim_class,\n",
    "    critic_optim_class,\n",
    "    HULoss(*scaled_HU_bounds, subopt_bs),\n",
    "    logger_interface,\n",
    "    val_batch_size,\n",
    "    weight_clip=weight_clip,\n",
    "    generator_lr_scheduler_class=generator_lr_scheduler_class,\n",
    "    critic_lr_scheduler_class=critic_lr_scheduler_class,\n",
    "    device=device,\n",
    "    checkpoint_every=None,\n",
    "    rng=rng,\n",
    ")\n",
    "\n",
    "# checkpoint_path = \"/home/marco/contrast-gan-3D/logs/model_checkpoints/9hnh7gto.pt\"\n",
    "# checkpoint_path = \"/home/marco/contrast-gan-3D/logs/model_checkpoints/07qiygyk.pt\"\n",
    "# checkpoint_path = train_u.find_latest_checkpoint(config.CHECKPOINTS_DIR / \"6en9vikh\")\n",
    "checkpoint_path = train_u.find_latest_checkpoint(config.CHECKPOINTS_DIR / \"17pgi67n\")\n",
    "checkpoint_path = Path(checkpoint_path)\n",
    "\n",
    "trainer.load_checkpoint(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_utils.count_parameters(trainer.critic))\n",
    "print(model_utils.count_parameters(trainer.generator))\n",
    "# print(trainer.critic)\n",
    "# print(\"-----------\")\n",
    "# print(trainer.generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(ScanType))\n",
    "patches = [next(chosen_loaders[scan_type.value]) for scan_type in ScanType]\n",
    "print([p[\"data\"].shape for p in patches])\n",
    "\n",
    "self = trainer\n",
    "iteration = 0\n",
    "\n",
    "opt_d, low_d, high_d = patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = low_d[\"data\"].to(device, non_blocking=True)\n",
    "attenuation_low: Tensor = self.generator(low)\n",
    "low, attenuation_low = utils.to_CPU(low), utils.to_CPU(attenuation_low)\n",
    "low_recon = low - attenuation_low\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high = high_d[\"data\"].to(device, non_blocking=True)\n",
    "attenuation_high: Tensor = self.generator(high)\n",
    "high, attenuation_high = utils.to_CPU(high), utils.to_CPU(attenuation_high)\n",
    "high_recon = high - attenuation_high\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    opt = opt_d[\"data\"].to(device, non_blocking=True)\n",
    "    attenuation_opt: Tensor = self.generator(opt)\n",
    "    opt, attenuation_opt = utils.to_CPU(opt), utils.to_CPU(attenuation_opt)\n",
    "    opt_recon = opt - attenuation_opt\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if self.train_log_sample_size is None:\n",
    "    self.train_log_sample_size = 64\n",
    "    if len(high_recon.shape) != 5:  # 2D case\n",
    "        bs = (len(x[\"data\"]) for x in patches)\n",
    "        self.train_log_sample_size = min(*bs, self.train_log_sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from contrast_gan_3D.utils import swap_last_dim\n",
    "\n",
    "print(swap_last_dim(cm.RdBu(torch.rand((1, 1, 512, 512, 128))).squeeze()).shape)\n",
    "print(swap_last_dim(cm.RdBu(torch.rand((1, 1, 512, 512, 6))).squeeze()).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.logger_interface(\n",
    "    patches,\n",
    "    [opt_recon, low_recon, high_recon],\n",
    "    [attenuation_opt, attenuation_low, attenuation_high],\n",
    "    list(ScanType),\n",
    "    iteration,\n",
    "    \"train\",\n",
    "    self.train_log_sample_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = logger_interface.logger.create_attenuation_grid(\n",
    "    scaler.unscale(opt_recon), [0, ..., slice(0, opt_recon.shape[-1], 2)], False\n",
    ")\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(desired_HU_bounds, scaler(np.array(desired_HU_bounds)))\n",
    "\n",
    "p = opt.ravel()[::10]\n",
    "p_unscaled = scaler.unscale(p)\n",
    "p_recon = scaler.unscale(opt_recon.ravel()[::10])\n",
    "name = opt_d[\"name\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axes[0].hist(p, bins=80)\n",
    "axes[0].set_title(\"Generator's input\")\n",
    "axes[1].hist(p_unscaled, bins=80)\n",
    "axes[1].set_title(\"Original\")\n",
    "axes[2].hist(p_recon, bins=80)\n",
    "axes[2].set_title(\"Reconstructed\")\n",
    "\n",
    "fig.suptitle(name)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# plt.savefig(savefolder / f\"{name}_hist.png\")\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d, tensor, rec_tensor, sc in zip(\n",
    "    [opt_d, low_d, high_d],\n",
    "    [opt, low, high],\n",
    "    [opt_recon, low_recon, high_recon],\n",
    "    ScanType,\n",
    "):\n",
    "    # fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    og_ctls = scaler.unscale(tensor[d[\"seg\"]])\n",
    "    recon_ctls = scaler.unscale(rec_tensor[d[\"seg\"]])\n",
    "    assert og_ctls.shape == recon_ctls.shape\n",
    "    # axes[0].hist(og_ctls, bins=80)\n",
    "    # axes[0].set_title(\"Original centerlines\")\n",
    "    # axes[1].hist(recon_ctls, bins=80)\n",
    "    # axes[1].set_title(\"Corrected centerlines\")\n",
    "\n",
    "    fig, axes = plt.subplots(figsize=(8, 5))\n",
    "    args = {\n",
    "        \"alpha\": 0.5,\n",
    "        \"bins\": 80,\n",
    "        # \"density\": True\n",
    "    }\n",
    "    axes.hist(og_ctls, label=\"Original\", **args)\n",
    "    axes.hist(recon_ctls, label=\"Corrected\", **args)\n",
    "    fig.legend()\n",
    "    fig.suptitle(d[\"name\"][0] + f\" {sc.name}\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan, meta = data_u.load_patient(low_d[\"path\"][0])\n",
    "print(meta[\"name\"], low_d[\"path\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrector_3D = CCTAContrastCorrector(\n",
    "    generator_class,\n",
    "    scaler,\n",
    "    device,\n",
    "    inference_patch_size=train_patch_size,\n",
    "    checkpoint_path=checkpoint_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_corrected = corrector_3D(scan[..., 0], desc=meta[\"name\"])\n",
    "print(scan.shape, high_corrected.shape)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefolder = Path(\"/home/marco/data/test_inference/\")\n",
    "corrector_3D.save_scan(\n",
    "    high_corrected, meta[\"offset\"], meta[\"spacing\"], savefolder / f\"{meta['name']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    folder = Path(\"/home/marco/thesis_project/contrast-gan-3D/assets\")\n",
    "\n",
    "    SHOW = True\n",
    "\n",
    "    for sc in ScanType:\n",
    "        print(sc)\n",
    "        print(\"----------------------------------\")\n",
    "        savefolder = folder / f\"{sc.name}_unnormed\"\n",
    "        savefolder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        for i in range(len(patches[sc.value][\"data\"])):\n",
    "            p = patches[sc.value][\"data\"][i]\n",
    "            p_seg = patches[sc.value][\"seg\"][i]\n",
    "            p_unscaled = scaler.unscale(p)\n",
    "            name = patches[sc.value][\"name\"][i]\n",
    "\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "            axes[0].hist(p.ravel()[::5], bins=80)\n",
    "            axes[0].set_title(\"Scaled\")\n",
    "            axes[1].hist(p_unscaled.ravel()[::5], bins=80)\n",
    "            axes[1].set_title(\"Original\")\n",
    "            fig.suptitle(name)\n",
    "            plt.tight_layout()\n",
    "            if SHOW:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.savefig(savefolder / f\"{name}_hist.png\")\n",
    "            plt.close(fig)\n",
    "\n",
    "            fig = viz.plot_axial_slices_and_centerlines(\n",
    "                p_unscaled[..., ::2],\n",
    "                p_seg[..., ::2],\n",
    "                # **logger_interface.logger.grid_args,\n",
    "                normalize=True,\n",
    "                value_range=(p_unscaled.min().item(), p_unscaled.max().item()),\n",
    "                cbar=True,\n",
    "            )\n",
    "            fig.suptitle(name)\n",
    "            plt.tight_layout()\n",
    "            if SHOW:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.savefig(savefolder / f\"{name}.png\")\n",
    "            plt.close(fig)\n",
    "\n",
    "            fig = logger_interface.logger.create_attenuation_grid(\n",
    "                p_unscaled, [0, ..., slice(0, 128, 2)], scale_by_factor=False\n",
    "            )\n",
    "            fig.suptitle(name)\n",
    "            plt.tight_layout()\n",
    "            if SHOW:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.savefig(savefolder / f\"{name}_attenuation.png\")\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_utils.compute_convolution_filters_shape(\n",
    "    trainer.critic, patches[0][\"data\"].shape[1:], show=True\n",
    ")\n",
    "print(\"----\")\n",
    "model_utils.compute_convolution_filters_shape(\n",
    "    trainer.generator, patches[0][\"data\"].shape[1:], show=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attenuations = trainer.generator(subopt)\n",
    "recon = subopt - attenuations\n",
    "\n",
    "print(attenuations[1].min(), attenuations[1].max())\n",
    "\n",
    "D_real  = trainer.critic(opt)\n",
    "D_fake = trainer.critic(recon.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "from contrast_gan_3D.model.utils import wgan_gradient_penalty\n",
    "\n",
    "loss_D = trainer.loss_GAN(D_fake, D_real)\n",
    "gp = wgan_gradient_penalty(\n",
    "    opt.repeat((2,) + (1,) * len(opt.shape[1:])),\n",
    "    recon,\n",
    "    trainer.critic,\n",
    "    trainer.device,\n",
    ")\n",
    "if False:\n",
    "    loss_D += gp\n",
    "\n",
    "\n",
    "# loss_D.backward()\n",
    "\n",
    "loss_G = -trainer.loss_GAN(trainer.critic(recon))\n",
    "# loss_G.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dot(gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# idea of 1D convolution: bottleneck!\n",
    "inp_shape = (256, 128, 128, 128)\n",
    "model_utils.print_convolution_filters_shape(nn.Conv3d(256, 64, 1, 1, 0), inp_shape)\n",
    "model_utils.print_convolution_filters_shape(nn.Conv3d(64, 64, 3, 1, 1), inp_shape)\n",
    "model_utils.print_convolution_filters_shape(nn.Conv3d(64, 256, 1, 1, 0), inp_shape)\n",
    "print('------')\n",
    "model_utils.print_convolution_filters_shape(nn.Conv3d(256, 256, 3, 1, 1), inp_shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
